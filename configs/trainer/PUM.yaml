defaults:
  - finetune

# Generic PUM orchestrator wrapping any inner unlearning method
handler: PUM
method_args:
  inner_handler: GradAscent   # override to GradDiff/NPO/DPO/RMU/UNDIAL/CEU/SatImp/WGA/PDU
  inner_method_args: {}       # optional kwargs forwarded to inner handler
  copies_m: 3                 # number of perturbed copies per round (m)
  rounds_R: 1                 # number of PUM rounds (R)
  sigma: 0.0                  # Gaussian noise std (per-parameter); 0.0 enables DP-based auto-calibration if dp_* provided
  # DP-based auto-calibration (single-sigma). If dp_epsilon, dp_delta, and dp_sensitivity_total_l2 are set
  # and sigma==0, the trainer will compute sigma to satisfy (epsilon,delta)-DP under the conservative S_alpha bound.
  dp_epsilon: null
  dp_delta: null
  dp_sensitivity_total_l2: null
  dp_rdp_orders: [1.1, 2, 4, 8, 16, 32, 64]
  dp_use_worstcase_alpha: true
  alpha_min: 1.0              # lower bound for secret scaling
  alpha_max: 1.1              # upper bound for secret scaling
  eta_srv: 1.0                # server update scale for aggregated delta
  local_epochs: 1             # local unlearning epochs per copy
  local_max_steps: null       # optional max steps per copy (overrides epochs if set)
  auto_balance_local_max_steps: true  # if true and local_max_steps is null, set local_max_steps so that local_max_steps * rounds_R ~= original total steps N
  clip_update_norm: null      # optional global l2 clip on each copy's delta
  use_orthogonal_reparam: false  # identity by default; safe to enable once implemented
